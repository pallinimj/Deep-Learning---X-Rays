{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIH_DenseNet_fine_tune_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mthomp89/NU_489_capstone/blob/develop_thompson/NIH_DenseNet_fine_tune_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgPc1deAztKd",
        "colab_type": "text"
      },
      "source": [
        "# Deep Transfer Learning on NIH Chest-Xray 8 Sample\n",
        "\n",
        "Two models for transfer learning are encompassed within this notebook: DenseNet121 and Inception_v3.\n",
        "\n",
        "Expected input shape for DenseNet121 is (224, 224)\n",
        "Expected input shape for Inception_v3 is (299, 299)\n",
        "\n",
        "Notebook consists of a data load, limited EDA, data pipeline (preprocessing and augmentation), and modeling using one of the above architectures at a time.\n",
        "\n",
        "Fine tuning of the selected model is also part of the notebook and consists of setting particular layers of the selected model as trainable.\n",
        "\n",
        "*Credits:*\n",
        "* *malgamves/DeepClassifyML https://github.com/malgamves/DeepClassifyML/blob/master/Inception_v3_fine_tune.ipynb*\n",
        "* *xhlulu https://www.kaggle.com/xhlulu/transfer-learning-with-densenet-keras*\n",
        "\n",
        "====================================================\n",
        "\n",
        "### **Do not run all cells**\n",
        "### **Several experimentations of modeling follows** \n",
        "### **Run only the model of interest then evaluate**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpaTe0LGqD38",
        "colab_type": "text"
      },
      "source": [
        "It should be noted that these images require some significant pre-processing and/or relabeling for best results. For this exercise we will do only minimal pre-processing of the images. See the following blogpost for more detail about specific challenges associated with this dataset: https://lukeoakdenrayner.wordpress.com/2017/12/18/the-chestxray14-dataset-problems/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqZCsclLk1B2",
        "colab_type": "text"
      },
      "source": [
        "## **TO-DOs**\n",
        "\n",
        "* Move notebook to Kaggle site and use full NIH Chest-Xray 8 dataset to mitigate overfitting\n",
        "* Figure out how to insert use the `BalancedDataGenerator` class (https://medium.com/analytics-vidhya/how-to-apply-data-augmentation-to-deal-with-unbalanced-datasets-in-20-lines-of-code-ada8521320c9)\n",
        "* Institute additional callbacks such as `EarlyStopping`, `ReduceLROnPlateau`, and `ModelCheckpoint` (https://www.kaggle.com/paultimothymooney/predicting-pathologies-in-x-ray-images)\n",
        "* Visualize or confirm by tensor that classes are balanced after using the `BalancedDataGenerator` class or the `sklearn.utils.class_weight` class \n",
        "* Experiment with `batch_size`, `momentum`, `learning rate`, `activation`, and `optimizer` \n",
        "* Experiment with adding another model such as VGG16 as the top layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTgG3zkuQcXq",
        "colab_type": "text"
      },
      "source": [
        "# Set environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J8YdJ0Lzrta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files \n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFcZJCqi3o3F",
        "colab_type": "text"
      },
      "source": [
        "**Import kaggle.json**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lVYNN-92C8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kThaXqK46sz",
        "colab_type": "text"
      },
      "source": [
        "**Wire-up Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S21WXnzh45-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D0Vy77Z4yR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeKNOUFO5t69",
        "colab_type": "text"
      },
      "source": [
        "**Verify json**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKs3yrzi4ybL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l ~/.kaggle\n",
        "!cat ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqiJ-Z3x50pt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle \n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgdT9UelIw-Y",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQglpFPjhtxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension to visualize evaluation of the model\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IazKNCANHgYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.data_utils import Sequence\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.keras import balanced_batch_generator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import os "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_xyJvD7a07a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BalancedDataGenerator(Sequence):\n",
        "    \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n",
        "    def __init__(self, x, y, datagen, batch_size=32):\n",
        "        self.datagen = datagen\n",
        "        self.batch_size = batch_size\n",
        "        self._shape = x.shape        \n",
        "        datagen.fit(x)\n",
        "        self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), batch_size=self.batch_size, keep_sparse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._shape[0] // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_batch, y_batch = self.gen.__next__()\n",
        "        x_batch = x_batch.reshape(-1, *self._shape[1:])\n",
        "        return self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKtnp1246OuI",
        "colab_type": "text"
      },
      "source": [
        "**Data load**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN-CtTCO8TPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/')\n",
        "!mkdir nih-chest-xrays"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzTY5Twa6T0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! kaggle datasets download -d nih-chest-xrays/sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do4TmrbN-rIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/nih-chest-xrays')\n",
        "!unzip -q sample.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME8nmn2xIo9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"sample_labels.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxAQ8VFGMhPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append image paths to csv; required for 'datagen.flow_from_dataframe'\n",
        "image_paths = {os.path.basename(x): x for x in \n",
        "                   glob(os.path.join('/content/drive/My Drive/nih-chest-xrays/images/', '*.png'))}\n",
        "print('Scans found:', len(image_paths), ', Total Headers', df.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hch6QT2nORRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['paths'] = df['Image Index'].map(image_paths.get)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiDSwFeTIJe4",
        "colab_type": "text"
      },
      "source": [
        "# EDA - Exploratory Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpiP2mCcKGy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4vujQ9hKOZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "des_df = df.describe()\n",
        "des_df.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWQFA2V-Oox5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize distribution of data\n",
        "\n",
        "label_counts = df['Finding Labels'].value_counts()[:15]\n",
        "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
        "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
        "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
        "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihvzZ854PIgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Finding Labels'] = df['Finding Labels'].map(lambda x: x.replace('No Finding',''))\n",
        "\n",
        "from itertools import chain\n",
        "all_labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
        "all_labels = [x for x in all_labels if len(x)>0]\n",
        "\n",
        "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
        "\n",
        "for c_label in all_labels:\n",
        "    if len(c_label)>1: # leave out empty labels\n",
        "       df[c_label] = df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
        "df.sample(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8j5LpgyV1PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eliminate observations having null values/no findings of disease\n",
        "\n",
        "#df = df[~df['Finding Labels'].str.contains('No Finding')]\n",
        "#df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R81cZe5WTBOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Weight dataset to achieve a normal distribution when sampling\n",
        "# Weight is 0.1 + number of findings\n",
        "\n",
        "#sample_weights = df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>100 else 0).values + 4e-2\n",
        "#sample_weights /= sample_weights.sum()\n",
        "#df = df.sample(df.shape[0], weights=sample_weights)\n",
        "\n",
        "# Visualize new distribution\n",
        "\n",
        "#label_counts = df['Finding Labels'].value_counts()[:15]\n",
        "#fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
        "#ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
        "#ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
        "#_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYIXEIVWMwjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#labels = pd.read_csv('sample_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FalpUJMKMeqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = labels[['Image Index','Finding Labels','Follow-up #','Patient ID','Patient Age','Patient Gender']]\n",
        "\n",
        "# Create new columns for each disease\n",
        "pathology_list = ['Cardiomegaly',\n",
        "                  'Emphysema',\n",
        "                  'Effusion',\n",
        "                  'Hernia',\n",
        "                  'Nodule',\n",
        "                  'Pneumothorax',\n",
        "                  'Atelectasis',\n",
        "                  'Pleural_Thickening',\n",
        "                  'Mass',\n",
        "                  'Edema',\n",
        "                  'Consolidation',\n",
        "                  'Infiltration',\n",
        "                  'Fibrosis',\n",
        "                  'Pneumonia']\n",
        "\n",
        "for pathology in pathology_list :\n",
        "    labels[pathology] = labels['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)\n",
        "\n",
        "# Remove `Y` after age\n",
        "labels['Age']=labels['Patient Age'].apply(lambda x: x[:-1]).astype(int)\n",
        "\n",
        "# Visualize dataset by disease by gender\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "gs = gridspec.GridSpec(8,1)\n",
        "ax1 = plt.subplot(gs[:7, :])\n",
        "ax2 = plt.subplot(gs[7, :])\n",
        "data1 = pd.melt(labels,\n",
        "             id_vars=['Patient Gender'],\n",
        "             value_vars = list(pathology_list),\n",
        "             var_name = 'Category',\n",
        "             value_name = 'Count')\n",
        "data1 = data1.loc[data1.Count>0]\n",
        "g=sns.countplot(y='Category',hue='Patient Gender',data=data1, ax=ax1, order = data1['Category'].value_counts().index)\n",
        "ax1.set( ylabel=\"\",xlabel=\"\")\n",
        "ax1.legend(fontsize=20)\n",
        "ax1.set_title('X Ray partition',fontsize=18);\n",
        "\n",
        "labels['Nothing']=labels['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)\n",
        "\n",
        "data2 = pd.melt(labels,\n",
        "             id_vars=['Patient Gender'],\n",
        "             value_vars = list(['Nothing']),\n",
        "             var_name = 'Category',\n",
        "             value_name = 'Count')\n",
        "data2 = data2.loc[data2.Count>0]\n",
        "g = sns.countplot(y='Category',hue='Patient Gender',data=data2,ax=ax2)\n",
        "ax2.set( ylabel=\"\",xlabel=\"Number of infected patient\")\n",
        "ax2.legend('')\n",
        "plt.subplots_adjust(hspace=.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5poKpu3K_jJ",
        "colab_type": "text"
      },
      "source": [
        "**Drop useless collumns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvm9p6XkK-2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_drop = df.drop(['Follow-up #',\n",
        "                   'Patient ID',\n",
        "                   'Patient Age',\n",
        "                   'Patient Gender',\n",
        "                   'View Position',\n",
        "                   'OriginalImageWidth',\n",
        "                   'OriginalImageHeight'\n",
        "                   ,'OriginalImagePixelSpacing_x',\n",
        "                   'OriginalImagePixelSpacing_y'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0NskoH4LneT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving cleaned csv\n",
        "df_drop.to_csv('/content/drive/My Drive/nih-chest-xrays/cleaned_sample.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfGW144JKkj0",
        "colab_type": "text"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIrL4tweVy3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/nih-chest-xrays/cleaned_sample.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rSy0olwKsHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a list of All labels\n",
        "df['Finding Labels'] = df['Finding Labels'].apply(lambda x: x.split('|'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs7BE64NZtpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.chdir('/content/drive/My Drive/nih-chest-xrays/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoSSJMOZMvKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and define image generators for data augmentation\n",
        "datagen = ImageDataGenerator(rescale = 1./255., \n",
        "                             samplewise_center=True,\n",
        "                             samplewise_std_normalization=True,\n",
        "                             horizontal_flip = True,\n",
        "                             vertical_flip = False,\n",
        "                             height_shift_range= 0.05,\n",
        "                             width_shift_range=0.1,\n",
        "                             rotation_range=5,\n",
        "                             shear_range = 0.1,\n",
        "                             fill_mode = 'reflect',\n",
        "                             zoom_range=0.15)\n",
        "\n",
        "\n",
        "\n",
        "train_gen = datagen.flow_from_dataframe(dataframe = df[:1900],\n",
        "                                        directory = '/content/drive/My Drive/nih-chest-xrays/',\n",
        "                                        x_col ='paths',\n",
        "                                        y_col ='Finding Labels',\n",
        "                                        batch_size = 64,\n",
        "                                        seed = 42,\n",
        "                                        shuffle = True,\n",
        "                                        class_mode = 'categorical',\n",
        "                                        classes = ['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion',\n",
        "                                                   'Emphysema', 'Fibrosis','Infiltration','Mass','Nodule','Pleural_Thickening',\n",
        "                                                   'Pneumonia','Pneumothorax'], \n",
        "                                        \n",
        "                                        # Inception_v3 target size = (299, 299)\n",
        "                                        #target_size = (299,299))\n",
        "                                        \n",
        "                                        # DenseNet121 target size = (224, 224)\n",
        "                                        target_size = (224, 224))\n",
        "\n",
        "\n",
        "valid_gen = datagen.flow_from_dataframe(dataframe = df[1900:2000],\n",
        "                                        directory = '/content/drive/My Drive/nih-chest-xrays/',\n",
        "                                        x_col ='paths',\n",
        "                                        y_col ='Finding Labels',\n",
        "                                        batch_size = 64,\n",
        "                                        seed = 42,\n",
        "                                        shuffle = True,\n",
        "                                        class_mode = 'categorical',\n",
        "                                        classes = ['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion',\n",
        "                                                   'Emphysema', 'Fibrosis','Infiltration','Mass','Nodule','Pleural_Thickening',\n",
        "                                                   'Pneumonia','Pneumothorax'],\n",
        "                                        \n",
        "                                        # Inception_v3 target size = (299, 299)\n",
        "                                        #target_size = (299,299))\n",
        "                                        \n",
        "                                        # DenseNet121 target size = (224, 224)\n",
        "                                        target_size = (224, 224))\n",
        "\n",
        "\n",
        "test_gen = datagen.flow_from_dataframe(dataframe = df[2000:],\n",
        "                                       directory = '/content/drive/My Drive/nih-chest-xrays/',\n",
        "                                       x_col ='paths',\n",
        "                                       y_col ='Finding Labels',\n",
        "                                       batch_size = 64,\n",
        "                                       seed = 42,\n",
        "                                       shuffle = True,\n",
        "                                       class_mode = 'categorical',\n",
        "                                       classes = ['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion',\n",
        "                                                  'Emphysema', 'Fibrosis','Infiltration','Mass','Nodule','Pleural_Thickening',\n",
        "                                                  'Pneumonia','Pneumothorax'],\n",
        "                                       \n",
        "                                       # Inception_v3 target size = (299, 299)\n",
        "                                       #target_size = (299,299))\n",
        "                                       \n",
        "                                       # DenseNet121 target size = (224, 224)\n",
        "                                       target_size = (224, 224))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdvWsdamzmuI",
        "colab_type": "text"
      },
      "source": [
        "# Balanced Data Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-G2JOoWepg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Balance dataset to achieve sampling from normal distributions across all classes\n",
        "\n",
        "#bgen = BalancedDataGenerator(x_col, y_col, datagen, batch_size=32)\n",
        "#BGEN_STEPS_PER_EPOCH = balanced_gen.steps_per_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH9DE2QHfabs",
        "colab_type": "text"
      },
      "source": [
        "# **STOP**\n",
        "Several experimentations of modeling follows. Run only the model of interest then evaluate. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXxLAbhYRmLZ",
        "colab_type": "text"
      },
      "source": [
        "# Modeling\n",
        "Select which of the two models by changing lines 5 and 6 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH_0WfXTRo-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "# Inception_v3 input tensor = (299, 299, 3)\n",
        "# DenseNet121 input tensor = (224, 224, 3)\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))  \n",
        "base_model = DenseNet121(input_tensor = input_tensor, weights = 'imagenet', include_top= False)\n",
        "\n",
        "# Add new layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation = 'relu')(x)\n",
        "drop = Dropout(0.5)(x)\n",
        "cl = Dense(13, activation = 'sigmoid')(drop)\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs = cl )\n",
        "\n",
        "# Train only the top layers (which were randomly initialized)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "model.compile(optimizer = 'rmsprop', loss ='binary_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewi9jKFpauwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define step sizes from each generator\n",
        "STEP_SIZE_TRAIN = train_gen.n//train_gen.batch_size\n",
        "STEP_SIZE_VALID = valid_gen.n//valid_gen.batch_size\n",
        "STEP_SIZE_TEST = test_gen.n//test_gen.batch_size\n",
        "\n",
        "# Balance dataset to achieve sampling from normal distributions across all classes\n",
        "# The sklearn.utils.class_weight class is another option to balance the dataset\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "               'balanced',\n",
        "                np.unique(train_gen.classes), \n",
        "                train_gen.classes)\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6602HYPiU8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CixAhLOkfTqf",
        "colab_type": "text"
      },
      "source": [
        "## Initial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDKGWECmfTHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training \n",
        "\n",
        "startTrainTime = time.time()\n",
        "\n",
        "history = model.fit_generator(generator = train_gen, steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "                   validation_data = valid_gen,\n",
        "                   validation_steps = STEP_SIZE_VALID,\n",
        "                   class_weight = class_weights,\n",
        "                   callbacks = [tensorboard_callback],\n",
        "                   epochs = 25)\n",
        "\n",
        "endTrainTime = time.time()\n",
        "trainTime = endTrainTime - startTrainTime\n",
        "print()\n",
        "print('Total Training Time (sec): {}'.format(trainTime))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pUGz2sgjtKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf3Ebw_5h-cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving model\n",
        "model.save_weights('initial_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L7jtVWgyHFu",
        "colab_type": "text"
      },
      "source": [
        "## Initial Training - Tuning\n",
        "Decrease epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFUYfP8uiuQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training \n",
        "\n",
        "#startTrainTime = time.time()\n",
        "\n",
        "#history = model.fit_generator(generator = train_gen, \n",
        "#                              steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "#                              validation_data = valid_gen,\n",
        "#                              validation_steps = STEP_SIZE_VALID,\n",
        "#                              class_weight = class_weights,\n",
        "#                              callbacks = [tensorboard_callback],\n",
        "#                              epochs = 5)\n",
        "\n",
        "#endTrainTime = time.time()\n",
        "#trainTime = endTrainTime - startTrainTime\n",
        "#print()\n",
        "#print('Total Training Time (sec): {}'.format(trainTime))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsVSTUJqj5ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRlis7rnxn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving model\n",
        "#model.save_weights('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5vf-rOuwJXR",
        "colab_type": "text"
      },
      "source": [
        " # Fine Tuning of Selected Model\n",
        "\n",
        "Up to this point, the selected model has been used as a feature selection model with only the added last two dense layers as trainable. This next section also sets the top convolutional layer of the selecte model as trainable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-4DrN4VpPJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Y2DKflpreg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set top convulation layers (313-on) as trainable\n",
        "for layer in model.layers[:313]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[313:]:\n",
        "   layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OOiCVgnomJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss ='binary_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4AWMfqUyxqL",
        "colab_type": "text"
      },
      "source": [
        "# Fine-Tuned Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTq-q0S5y41f",
        "colab_type": "text"
      },
      "source": [
        "## Tuned Training - Round 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro8TYjFFowgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startTrainTime = time.time()\n",
        "\n",
        "history = model.fit_generator(generator = train_gen, \n",
        "                              steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "                              class_weight = class_weights,\n",
        "                              validation_data = valid_gen,\n",
        "                              validation_steps = STEP_SIZE_VALID,\n",
        "                              callbacks = [tensorboard_callback],\n",
        "                              epochs = 25)\n",
        "\n",
        "endTrainTime = time.time()\n",
        "trainTime = endTrainTime - startTrainTime\n",
        "print()\n",
        "print('Total Training Time (sec): {}'.format(trainTime))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkFuL18AjfIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B5JW8XozYgR",
        "colab_type": "text"
      },
      "source": [
        "## Tuned Training - Round 2\n",
        "Decrease epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc-lbDAbqhl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#startTrainTime = time.time()\n",
        "\n",
        "#history = model.fit_generator(generator = train_gen, \n",
        "#                              steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "#                              validation_data = valid_gen,\n",
        "#                              validation_steps = STEP_SIZE_VALID,\n",
        "#                              class_weight = class_weights,\n",
        "#                              callbacks = [tensorboard_callback],\n",
        "#                              epochs = 10)\n",
        "\n",
        "#endTrainTime = time.time()\n",
        "#trainTime = endTrainTime - startTrainTime\n",
        "#print()\n",
        "#print('Total Training Time (sec): {}'.format(trainTime))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqI2D9SWjUF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyvBMjkjxOtR",
        "colab_type": "text"
      },
      "source": [
        "## Set All Layers as Trainable\n",
        "\n",
        "Finally and just for experimentation, the entire selected model is set as trainable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qngCf2NBrLdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "   layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8vOTQILrnxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss ='binary_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9xyc2Z9rY8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startTrainTime = time.time()\n",
        "\n",
        "history = model.fit_generator(generator = train_gen, steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "                   validation_data = valid_gen,\n",
        "                   validation_steps = STEP_SIZE_VALID,\n",
        "                   class_weight = class_weights,\n",
        "                   callbacks = [tensorboard_callback],\n",
        "                   epochs = 5)\n",
        "\n",
        "endTrainTime = time.time()\n",
        "trainTime = endTrainTime - startTrainTime\n",
        "print()\n",
        "print('Total Training Time (sec): {}'.format(trainTime))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhFmY77sjQKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28oLsHvnxn_D",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYJQkMAss8Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate_generator(generator = test_gen,\n",
        "                                   steps = STEP_SIZE_TEST)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCzVJirzwo3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnBeO8OnszIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7qjkHMvs_JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjwlLtdiwjeG",
        "colab_type": "text"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M13ZyzNswvF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/nih-chest-xrays/')\n",
        "\n",
        "# Inception_v3 input tensor = (299, 299, 3)\n",
        "# DenseNet121 input tensor = (224, 224, 3)\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))  \n",
        "base_model = DenseNet121(input_tensor = input_tensor,weights = 'imagenet', include_top= False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation = 'relu')(x)\n",
        "drop = Dropout(0.5)(x)\n",
        "cl = Dense(13, activation = 'sigmoid')(drop)\n",
        "model = Model(inputs=input_tensor, outputs = cl )\n",
        "  \n",
        "\n",
        "model.load_weights('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXQkg_d9xKXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss ='binary_crossentropy', metrics= ['accuracy'])\n",
        "pred = model.evaluate_generator(generator = test_gen,\n",
        "                                steps = STEP_SIZE_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ2S3SGs0BeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1-0SYKxBE0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting prections\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "img_path = '/content/drive/My Drive/nih-chest-xrays/images/00000030_001.png'\n",
        "\n",
        "# Inception_v3 input tensor = (299, 299, 3)\n",
        "# DenseNet121 input tensor = (224, 224, 3)\n",
        "\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "preds = model.predict(x)\n",
        "preds = preds.astype(float)*100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fibeqhhpIScY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAjMRYI555Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_true = train_gen.classes\n",
        "\n",
        "confusion_matrix(y_true, preds)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}